{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b36132-c12c-41da-bf4a-877ad42d2bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Question-Answering-Project\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5084ce7a-ffda-4195-9f46-b12e96271054",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514259fc-0839-4d75-9404-173f41fd380e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04e7624e-b3c3-40d5-9b17-498c71d68db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae799c21-31af-4667-b6ab-9fddda000b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_datasets[\"train\"][2:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d23ffd22-f7aa-44b1-8f2b-784afa34eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311566d5-0e39-4501-99a1-de985bc0a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e48c7d-8256-4d95-8356-6ea08c88e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31918fa-2343-40cb-a6df-3c1d98722903",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35a4724-ca59-4cb6-a544-8830a5096198",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = raw_datasets[\"train\"][0][\"context\"]\n",
    "question = raw_datasets[\"train\"][0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ad7571-cfb3-41e4-9a75-6f9bfe027ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0135b14f-99ac-45d0-accd-9d9a21d8ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = raw_datasets[\"train\"][2:6][\"context\"]\n",
    "question = raw_datasets[\"train\"][2:6][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a6ecbce-c409-4f6c-8617-88f42077e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ba8e877-d5d6-4637-9c53-958859568a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f5e170e-ed34-4e3e-8ad3-6019c2e9e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = raw_datasets[\"train\"][2:6][\"answers\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca3910b8-d02c-474d-a7dd-be360478d03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ['the Main Building'], 'answer_start': [279]},\n",
       " {'text': ['a Marian place of prayer and reflection'], 'answer_start': [381]},\n",
       " {'text': ['a golden statue of the Virgin Mary'], 'answer_start': [92]},\n",
       " {'text': ['September 1876'], 'answer_start': [248]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "988cdfa6-790a-41c1-8fb8-3de4640bb285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['5733be284776f41900661180',\n",
       "  '5733be284776f41900661181',\n",
       "  '5733be284776f4190066117e',\n",
       "  '5733bf84d058e614000b61be'],\n",
       " 'title': ['University_of_Notre_Dame',\n",
       "  'University_of_Notre_Dame',\n",
       "  'University_of_Notre_Dame',\n",
       "  'University_of_Notre_Dame'],\n",
       " 'context': ['Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "  'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "  'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       "  \"As at most other universities, Notre Dame's students run a number of news media outlets. The nine student-run outlets include three newspapers, both a radio and television station, and several magazines and journals. Begun as a one-page journal in September 1876, the Scholastic magazine is issued twice monthly and claims to be the oldest continuous collegiate publication in the United States. The other magazine, The Juggler, is released twice a year and focuses on student literature and artwork. The Dome yearbook is published annually. The newspapers have varying publication interests, with The Observer published daily and mainly reporting university and other news, and staffed by students from both Notre Dame and Saint Mary's College. Unlike Scholastic and The Dome, The Observer is an independent publication and does not have a faculty advisor or any editorial oversight from the University. In 1987, when some students believed that The Observer began to show a conservative bias, a liberal newspaper, Common Sense was published. Likewise, in 2003, when other students believed that the paper showed a liberal bias, the conservative paper Irish Rover went into production. Neither paper is published as often as The Observer; however, all three are distributed to all students. Finally, in Spring 2008 an undergraduate journal for political science research, Beyond Politics, made its debut.\"],\n",
       " 'question': ['The Basilica of the Sacred heart at Notre Dame is beside to which structure?',\n",
       "  'What is the Grotto at Notre Dame?',\n",
       "  'What sits on top of the Main Building at Notre Dame?',\n",
       "  'When did the Scholastic Magazine of Notre dame begin publishing?'],\n",
       " 'answers': [{'text': ['the Main Building'], 'answer_start': [279]},\n",
       "  {'text': ['a Marian place of prayer and reflection'], 'answer_start': [381]},\n",
       "  {'text': ['a golden statue of the Virgin Mary'], 'answer_start': [92]},\n",
       "  {'text': ['September 1876'], 'answer_start': [248]}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_datasets = raw_datasets[\"train\"][2:6]\n",
    "sample_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46eba209-a8c5-4b7f-a3e6-b6b69567e687",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (199559200.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[18], line 20\u001b[1;36m\u001b[0m\n\u001b[1;33m    idx = 0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "start_positions = []\n",
    "end_positions = []\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n",
    "    answer = answers[sample_idx]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\"\"\"\n",
    "i  0 -> 18 , offset [(0, 0), (0, 3), (4, 12), (13, 15), (16, 19), (20, 26), (27, 32), (33, 35), (36, 41),...]\n",
    "i [cls][question][sep][context][sep]      [cls] [sep] (0,0)\n",
    "sample_idx 0000 1111 2222 3333333 và trong các feature của overflow thì có chứa các offset - các tupple là các subword từ 1 từ gốc\n",
    "answer -> {'answer text'}, 'answer_start': [start_char]} x4 x4 x4 x7 tại vì có 4 câu\n",
    "-> start_char  279 381 92 248\n",
    "answer[\"text\"] = [\"The Main Building\"], ... -> answer[\"text\"][0] chỉ là cái str ở trong các cái list thôi -> len answer\n",
    "end_char = start_char + len answer\n",
    "sequece_ids -> [None,0,0,0,0,0,0,None,1,1,1,1,1,1,..,1,None] phần 0 là question phần 1 là context\n",
    "\"\"\"\n",
    "    # Find the start and the end of the context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "        idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "        idx += 1\n",
    "    context_end = idx - 1\n",
    "\"\"\"\n",
    "sequence_ids[0] sẽ là ra 19 cái None, sequence_ids[idx] nó sẽ là slice qua các tokens trong cái sequence đấy và loop cho đủ tất cả các sequence của ta (ở đây là có 19 cái đấy)\n",
    "idx += 1 là để ta nhích dần lên đến khi nào sequence_ids[idx] = 1 là bắt đầu phần context của sequence đấy, khi đấy cái while loop sẽ dừng và ta có context_start\n",
    "còn khi mà đến token là None thì idx đấy -1 sẽ ra token cuối cùng của context\n",
    "\"\"\"\n",
    "\n",
    "     # If the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # Otherwise it's the start and end token positions\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\"\"\"\n",
    "if: nếu mà sequence đó mà thỏa mãn các điều kiện đó thì answer không nằm trong sequence đó -> label của sequence đó sẽ là (0,0)\n",
    "context_start <= context_end nghĩa là while loop cho đến khi idx nhỏ hơn idx của context end (ta đi qua từng offset một cho đến cuối cái sequence, context_start và context_end chỉ là index của offset thôi, còn star/end char là inputs_ids)\n",
    "- offset[idx] -> là trả lại cái offset tức cái tuple ở vị trí idx đó và offset[idx][0] là cái subword đầu tiên của cái cụm gốc đấy -> và ta loop (idx+=1) cho đến khi cái offset của chúng ta chạm đến start của answer\n",
    "\"\"\"\n",
    "\n",
    "start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b34b201c-b5fe-41a0-a770-9c8ebd2d7289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n([83, 51, 19, 0, 0, 64, 27, 0, 34, 0, 0, 0, 67, 34, 0, 0, 0, 0, 0],\\n [85, 53, 21, 0, 0, 70, 33, 0, 40, 0, 0, 0, 68, 35, 0, 0, 0, 0, 0])\\n\\nđây chính là đang label cho train data của mình\\nnhìn theo cặp dọc nhé: (83, 85) là của sequence đầu tiên\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = raw_datasets[\"train\"][2:6][\"answers\"]\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n",
    "    answer = answers[sample_idx]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # Find the start and end of the context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "        idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "        idx += 1\n",
    "    context_end = idx - 1\n",
    "\n",
    "    # If the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # Otherwise it's the start and end token positions\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "start_positions, end_positions\n",
    "\n",
    "\"\"\"\n",
    "([83, 51, 19, 0, 0, 64, 27, 0, 34, 0, 0, 0, 67, 34, 0, 0, 0, 0, 0],\n",
    " [85, 53, 21, 0, 0, 70, 33, 0, 40, 0, 0, 0, 68, 35, 0, 0, 0, 0, 0])\n",
    "\n",
    "đây chính là đang label cho train data của mình\n",
    "nhìn theo cặp dọc nhé: (83, 85) là của sequence đầu tiên\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5a5a59b-58a8-482f-8289-98c3c10e90a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: the Main Building, labels give: the Main Building\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ninputs[\"overflow_to_sample_mapping\"] [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]\\nanswers[sample_idx] {\\'text\\': [\\'the Main Building\\'], \\'answer_start\\': [279]} -> answer: \"the Main Building\"\\nstart -> 83\\nend -> 85\\ninputs[\"input_ids\"][0] -> dãy ids của sequnce ở idx 0 -> [start : end + 1] là lấy ids của answers xong decode ra \\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "start = start_positions[idx]\n",
    "end = end_positions[idx]\n",
    "labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")\n",
    "\"\"\"\n",
    "inputs[\"overflow_to_sample_mapping\"] [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3]\n",
    "answers[sample_idx] {'text': ['the Main Building'], 'answer_start': [279]} -> answer: \"the Main Building\"\n",
    "start -> 83\n",
    "end -> 85\n",
    "inputs[\"input_ids\"][0] -> dãy ids của sequnce ở idx 0 -> [start : end + 1] là lấy ids của answers xong decode ra \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b15ac34-c864-4f5b-a2e7-5aefa993fc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1109, 19349, 1104, 1103, 11373, 1762, 1120, 10360, 8022, 1110, 3148, 1106, 1134, 2401, 136, 102, 22182, 1193, 117, 1103, 1278, 1144, 170, 2336, 1959, 119, 1335, 4184, 1103, 4304, 4334, 112, 188, 2284, 10945, 1110, 170, 5404, 5921, 1104, 1103, 6567, 2090, 119, 13301, 1107, 1524, 1104, 1103, 4304, 4334, 1105, 4749, 1122, 117, 1110, 170, 7335, 5921, 1104, 4028, 1114, 1739, 1146, 14089, 5591, 1114, 1103, 7051, 107, 159, 21462, 1566, 24930, 2508, 152, 1306, 3965, 107, 119, 5893, 1106, 1103, 4304, 4334, 1110, 1103, 19349, 1104, 1103, 11373, 4641, 119, 13301, 1481, 1103, 171, 17506, 102]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07404c2f-8e55-47de-8349-ab9088f34bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mustang\n"
     ]
    }
   ],
   "source": [
    "car = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "\n",
    "model = car.pop(\"model\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff1e83b-4be9-4694-bc54-bc349feb0d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['56be4db0acb8001400a502ee',\n",
       "  '56be4db0acb8001400a502ef',\n",
       "  '56be4db0acb8001400a502f0',\n",
       "  '56be8e613aeaaa14008c90d1'],\n",
       " 'title': ['Super_Bowl_50', 'Super_Bowl_50', 'Super_Bowl_50', 'Super_Bowl_50'],\n",
       " 'context': ['Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       "  'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       "  'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.',\n",
       "  'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'],\n",
       " 'question': ['Where did Super Bowl 50 take place?',\n",
       "  'Which NFL team won Super Bowl 50?',\n",
       "  'What color was used to emphasize the 50th anniversary of the Super Bowl?',\n",
       "  'What was the theme of Super Bowl 50?'],\n",
       " 'answers': [{'text': ['Santa Clara, California',\n",
       "    \"Levi's Stadium\",\n",
       "    \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"],\n",
       "   'answer_start': [403, 355, 355]},\n",
       "  {'text': ['Denver Broncos', 'Denver Broncos', 'Denver Broncos'],\n",
       "   'answer_start': [177, 177, 177]},\n",
       "  {'text': ['gold', 'gold', 'gold'], 'answer_start': [488, 488, 521]},\n",
       "  {'text': ['\"golden anniversary\"', 'gold-themed', '\"golden anniversary'],\n",
       "   'answer_start': [487, 521, 487]}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_valid_datasets = raw_datasets[\"validation\"][2:6]\n",
    "sample_valid_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74f5f47b-aa29-4909-a5b0-2f3514edc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aef664f0-71c5-41a3-bd09-251f7d5ad67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "        sample_valid_datasets[\"question\"],\n",
    "        sample_valid_datasets[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbcdfb92-fc4d-4b1a-90bc-0c388f318e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "sample_map\n",
    "\n",
    "#Tại ở đây mình để max_length lớn hơn nên mỗi sample sẽ là câu trọn vẹn chứ không bị truncate như khi mình set max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4fb76ff6-cfcf-4910-a65a-006a274095c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'examples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])):\n\u001b[0;32m      3\u001b[0m         sample_idx \u001b[38;5;241m=\u001b[39m sample_map[i]\n\u001b[1;32m----> 4\u001b[0m         example_ids\u001b[38;5;241m.\u001b[39mappend(\u001b[43mexamples\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m][sample_idx])\n\u001b[0;32m      6\u001b[0m         sequence_ids \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39msequence_ids(i)\n\u001b[0;32m      7\u001b[0m         offset \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffset_mapping\u001b[39m\u001b[38;5;124m\"\u001b[39m][i]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'examples' is not defined"
     ]
    }
   ],
   "source": [
    "example_ids = []\n",
    "for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "        inputs[\"example_id\"] = example_ids\n",
    "\n",
    "\"\"\"\n",
    "inputs[\"input_ids\"] -> inputs ids của 4 sample có dạng [[sample1],[sample2],[sample3],[sample4]]\n",
    "len(inputs[\"input_ids\"]) -> 4 \n",
    "example_ids append \n",
    "examples là cái validation set của chúng ta có 1 cái id cùng sample index sẽ trả lại 1 cái id '56be8e613aeaaa14008c90d1'\n",
    "sequence_ids -> sẽ ra dạng [None,0,0,..,0,None,1,1,..,1,None] -> đại diện cho [CLS,Question, context, answer,sep] answer sẽ trả về toàn None\n",
    "offset sẽ trả về nguyên offset của cái sample đấy\n",
    "enumerate offset\n",
    "mỗi cái tuple offset có 1 index, nếu vị trí tương tự ở bên sequence_ids = 1, tức là vị trí của context -> thì sẽ thay vào offset mapping của trong inputs = o không thì là None, nghĩa là mình tạo offset var cho clean thôi chứ thực chất thì\n",
    "là loop qua chính inputs[\"offset_mapping\"] và với index trong sequence_ids là context thì return lại sang bên\n",
    "\n",
    "They will contain offsets for the question and the context, but once we’re in the post-processing stage we won’t have any way to know which part of the input IDs corresponded to the context and which part was the question (the sequence_ids() method we used is available for the output of the tokenizer only).\n",
    "So, we’ll set the offsets corresponding to the question to None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e6b97da-dc2b-475c-bb32-15bbf3547fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[43msample_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m sample_idx\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sample_idx = sample_map[5]\n",
    "sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "28bb0826-07db-4cba-a74e-1c38db28c374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'56be8e613aeaaa14008c90d1'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_valid_datasets[\"id\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ebaa6676-52b5-472f-92df-af322c902de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = inputs[\"offset_mapping\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0ea90466-7c26-4dcc-861a-4b8b089255a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "025a43de-a7a3-4c75-822f-ca588d5c1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a0b9029-82b8-438a-b457-9877a0872d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 87599/87599 [00:55<00:00, 1580.07 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(87599, 88729)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = raw_datasets[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96f658c2-5b67-4908-a982-edc586f083bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 88729\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55b1c4b-71d1-44b0-857e-079ce8236e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f397fd07-79a3-4c83-9226-bf5775e03f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 10570/10570 [00:13<00:00, 791.52 examples/s]\n"
     ]
    }
   ],
   "source": [
    "validation_dataset = raw_datasets[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b45dd6ab-73ea-44ae-8401-3c4a07ef1fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
       "    num_rows: 10822\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c6c1070b-7d2f-46cb-b773-629c49c31326",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = raw_datasets[\"train\"][2:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "414ce119-8c7b-41aa-91a8-62bcb8603d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[100], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mraw_datasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(\n\u001b[0;32m      2\u001b[0m     preprocess_training_examples,\n\u001b[0;32m      3\u001b[0m     batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     remove_columns\u001b[38;5;241m=\u001b[39mraw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[0;32m      5\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mlen\u001b[39m(raw_datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;28mlen\u001b[39m(train_dataset)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "train_dataset = raw_datasets.map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")\n",
    "len(raw_datasets[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dc15ca88-bad7-43e2-ab61-8314e1e9f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31a403-c649-40ab-b313-cab661406311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
